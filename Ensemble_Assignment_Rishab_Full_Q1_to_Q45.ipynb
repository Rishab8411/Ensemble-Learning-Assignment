{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "33864867",
   "metadata": {},
   "source": [
    "## Ensemble Learning Assignment – Rishab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a5e34db",
   "metadata": {},
   "source": [
    "### Theoretical Questions (Q1–Q20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45ce401c",
   "metadata": {},
   "source": [
    "\n",
    "**1. Can we use Bagging for regression problems?**  \n",
    "Yes, Bagging can be used for regression by combining the predictions of several regressors and averaging their outputs.\n",
    "\n",
    "**2. What is the difference between multiple model training and single model training?**  \n",
    "Multiple model training combines several models to improve accuracy, while single model training relies on one model that may overfit or underperform.\n",
    "\n",
    "**3. Explain the concept of feature randomness in Random Forest?**  \n",
    "In Random Forest, each tree uses a random subset of features while splitting, which helps in creating diverse models and avoids overfitting.\n",
    "\n",
    "**4. What is OOB (Out-of-Bag) Score?**  \n",
    "OOB score is an internal evaluation method in Bagging/Random Forest that uses unused samples (in bootstrap) to estimate the model's performance.\n",
    "\n",
    "**5. How can you measure the importance of features in a Random Forest model?**  \n",
    "Feature importance is measured by how much each feature decreases impurity across all trees in the forest.\n",
    "\n",
    "**6. Explain the working principle of a Bagging Classifier?**  \n",
    "A Bagging Classifier trains multiple base models on different random samples of the data and combines their outputs using majority voting.\n",
    "\n",
    "**7. How do you evaluate a Bagging Classifier’s performance?**  \n",
    "By using accuracy, precision, recall, F1-score, cross-validation, or confusion matrix on test data.\n",
    "\n",
    "**8. How does a Bagging Regressor work?**  \n",
    "It trains several regressors on different bootstrap samples and averages their predictions for final output.\n",
    "\n",
    "**9. What is the main advantage of ensemble techniques?**  \n",
    "They reduce variance and bias, improve prediction accuracy, and make the model more robust.\n",
    "\n",
    "**10. What is the main challenge of ensemble methods?**  \n",
    "They can be computationally expensive and harder to interpret compared to simpler models.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d03c6007",
   "metadata": {},
   "source": [
    "\n",
    "**11. Explain the key idea behind ensemble techniques.**  \n",
    "The key idea is to combine multiple models to get better and more stable predictions than a single model.\n",
    "\n",
    "**12. What is a Random Forest Classifier?**  \n",
    "It is an ensemble method that builds multiple decision trees and uses majority voting to predict the final class.\n",
    "\n",
    "**13. What are the main types of ensemble techniques?**  \n",
    "Bagging, Boosting, and Stacking.\n",
    "\n",
    "**14. What is ensemble learning in machine learning?**  \n",
    "Ensemble learning combines several models to improve overall performance.\n",
    "\n",
    "**15. When should we avoid using ensemble methods?**  \n",
    "When the dataset is small, model interpretability is critical, or we have limited computing resources.\n",
    "\n",
    "**16. How does Bagging help in reducing overfitting?**  \n",
    "It trains models on random subsets, so the final model is less sensitive to noise and overfitting is reduced.\n",
    "\n",
    "**17. Why is Random Forest better than a single Decision Tree?**  \n",
    "It combines results of many trees, reducing overfitting and improving accuracy.\n",
    "\n",
    "**18. What is the role of bootstrap sampling in Bagging?**  \n",
    "Bootstrap sampling randomly selects data points (with replacement) for training each model.\n",
    "\n",
    "**19. What are some real-world applications of ensemble techniques?**  \n",
    "Spam detection, fraud detection, medical diagnosis, image recognition, and recommendation systems.\n",
    "\n",
    "**20. What is the difference between Bagging and Boosting?**  \n",
    "Bagging trains models in parallel to reduce variance. Boosting trains sequentially to reduce bias.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "553f6579",
   "metadata": {},
   "source": [
    "### Practical Questions (Q21–Q45) – Code Only with Output"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
